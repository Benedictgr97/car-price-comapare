{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell to get the output\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import traceback\n",
    "import cloudscraper\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from decimal import Decimal\n",
    "from re import sub\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "postcode_buy=\"MK36JS\" \n",
    "radius_buy=10\n",
    "\n",
    "postcode_sell=\"DT13GJ\" \n",
    "radius_sell=25\n",
    "\n",
    "#Remeber to check the maximum and minimum years allowed on the website \n",
    "min_year=2008\n",
    "max_year=2015\n",
    "\n",
    "min_price=500\n",
    "max_price=2000\n",
    "\n",
    "#State how many brands/ models you want to show in the final graphs \n",
    "no_brands = 50\n",
    "no_models = 50\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postcode_add(df,postcode):\n",
    "    #Loop over the column names and add the postcode to each \n",
    "    for i in df.columns:\n",
    "        concat_col = i + ' ' + postcode\n",
    "        df = df.rename({i: concat_col.replace(' ','_')}, axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "#function to retrieve cars based on parameters put in \n",
    "def retrieve_cars(postcode, radius, min_year, max_year, min_price, max_price,location_type):\n",
    "    \"\"\"\n",
    "    Retrieve car listings based on specified search parameters.\n",
    "    \"\"\"\n",
    "    cars = get_cars(\n",
    "        postcode=postcode,\n",
    "        radius=radius,\n",
    "        min_year=min_year,\n",
    "        max_year=max_year,\n",
    "        min_price=min_price,\n",
    "        max_price=max_price\n",
    "    )\n",
    "    # Clean up year and brand columns\n",
    "    cars['year'] = cars['year'].dropna().apply(lambda x: int(str(x).split('(')[0]))\n",
    "    cars['brand'] = cars['name'].apply(lambda x: x.split(' ')[0])\n",
    "    cars['postcode'] = postcode\n",
    "    cars = postcode_add(cars,location_type)\n",
    "    \n",
    "    return cars\n",
    "\n",
    "def get_cars(\n",
    "    make = \"\",\n",
    "    model = \"\",\n",
    "    postcode=\"SW1A 0AA\", \n",
    "    radius=1500, \n",
    "    min_year=1995, \n",
    "    max_year=1995, \n",
    "    include_writeoff=\"exclude\",\n",
    "    verbose=False,\n",
    "    min_price= 0,\n",
    "    max_price = 99999):\n",
    "\n",
    "    # To bypass Cloudflare protection\n",
    "    scraper = cloudscraper.create_scraper()\n",
    "\n",
    "    # Basic variables\n",
    "    results = []\n",
    "    n_this_year_results = 0\n",
    "\n",
    "    url = \"https://www.autotrader.co.uk/car-search?advertising-location=at_cars&exclude-delivery-option=on\"\n",
    "\n",
    "    keywords = {}\n",
    "    keywords[\"mileage\"] = [\"miles\"]\n",
    "    keywords[\"transmission\"] = [\"Automatic\", \"Manual\"]\n",
    "    keywords[\"year\"] = [\" reg)\"]\n",
    "    keywords[\"engine\"] = [\"engine\"]\n",
    "\n",
    "    # Set up parameters for query to autotrader.co.uk\n",
    "    params = {\n",
    "        \"sort\": \"relevance\",\n",
    "        \"postcode\": postcode,\n",
    "        \"price-from\" : min_price,\n",
    "        \"price-to\" : max_price,\n",
    "        \"radius\": radius,\n",
    "        \"make\": make,\n",
    "        \"model\": model,\n",
    "        \"search-results-price-type\": \"total-price\",\n",
    "        \"search-results-year\": \"select-year\",\n",
    "        \"exclude-writeoff-categories\": \"on\"\n",
    "    }\n",
    "\n",
    "    year = min_year\n",
    "    page = 1\n",
    "    attempt = 1\n",
    "    \n",
    "    try:\n",
    "        while year <= max_year:\n",
    "            params[\"year-from\"] = year\n",
    "            params[\"year-to\"] = year\n",
    "            params[\"page\"] = page\n",
    "            \n",
    "\n",
    "            r = scraper.get(url, params=params)\n",
    "            if verbose:\n",
    "                print(\"Year:     \", year)\n",
    "                print(\"Page:     \", page)\n",
    "                print(\"Response: \", r)\n",
    "\n",
    "            try:\n",
    "                if r.status_code != 200:   # If not successful (e.g. due to bot protection)\n",
    "                    print(r.status_code)\n",
    "\n",
    "                    attempt = attempt + 1  # Log as an attempt\n",
    "\n",
    "                    if attempt <= 5:\n",
    "                        if verbose:\n",
    "                            print(\"Exception. Starting attempt #\", attempt, \"and keeping at page #\", page)\n",
    "                    \n",
    "                    else:\n",
    "                        page = page + 1\n",
    "                        attempt = 1\n",
    "                        if verbose:\n",
    "                            print(\"Exception. All attempts exhausted for this page. Skipping to next page #\", page)\n",
    "\n",
    "                if r.status_code == 404:\n",
    "                    print(r.url)\n",
    "\n",
    "                else:\n",
    "                    j = r.content\n",
    "                    \n",
    "                    s = BeautifulSoup(j, features=\"html.parser\")\n",
    "                    \n",
    "                    articles = s.find_all(\"article\", attrs={\"data-standout-type\":\"\"})\n",
    "\n",
    "                    # If no results or reached end of results...\n",
    "                    if len(articles) == 0 or r.url[r.url.find(\"page=\")+5:] != str(page):\n",
    "                        if verbose:\n",
    "                            print(\"Found total\", n_this_year_results, \"results for year\", year, \"across\", page-1, \"pages\")\n",
    "                            if year+1 <= max_year:\n",
    "                                print(\"Moving on to year\", year + 1)\n",
    "                                print(\"---------------------------------\")\n",
    "\n",
    "                        # Increment year and reset relevant variables\n",
    "                        type(year)\n",
    "                        year = year + 1\n",
    "                        page = 1\n",
    "                        attempt = 1\n",
    "                        n_this_year_results = 0\n",
    "                    else:\n",
    "                        for article in articles:\n",
    "                            print(article)\n",
    "                            print(2)\n",
    "                            car = {}\n",
    "                            car[\"name\"] = article.find(\"h3\", {\"class\": \"product-card-details__title\"}).text.strip()             \n",
    "                            car[\"link\"] = \"https://www.autotrader.co.uk\" + \\\n",
    "                                    article.find(\"a\", {\"class\": \"listing-fpa-link\"})[\"href\"][: article.find(\"a\", {\"class\": \"listing-fpa-link\"})[\"href\"] \\\n",
    "                                    .find(\"?\")]\n",
    "                            car[\"price\"] = int(sub(r'[^\\d.]', '', article.find(\"div\", {\"class\": \"product-card-pricing__price\"}).text.strip()))\n",
    "\n",
    "                            seller_info = article.find(\"ul\", {\"class\": \"product-card-seller-info__specs\"}).text.strip()\n",
    "                            car[\"seller\"] = \" \".join(seller_info.split())\n",
    "\n",
    "                            key_specs_bs_list = article.find(\"ul\", {\"class\": \"listing-key-specs\"}).find_all(\"li\")\n",
    "\n",
    "                            for key_spec_bs_li in key_specs_bs_list:\n",
    "\n",
    "                                key_spec_bs = key_spec_bs_li.text\n",
    "\n",
    "                                if any(keyword in key_spec_bs for keyword in keywords[\"mileage\"]):\n",
    "                                    car[\"mileage\"] = int(key_spec_bs[:key_spec_bs.find(\" miles\")].replace(\",\",\"\"))\n",
    "                                elif any(keyword in key_spec_bs for keyword in keywords[\"BHP\"]):\n",
    "                                    car[\"BHP\"] = int(key_spec_bs[:key_spec_bs.find(\"BHP\")])\n",
    "                                elif any(keyword in key_spec_bs for keyword in keywords[\"transmission\"]):\n",
    "                                    car[\"transmission\"] = key_spec_bs\n",
    "                                elif any(keyword in key_spec_bs for keyword in keywords[\"fuel\"]):\n",
    "                                    car[\"fuel\"] = key_spec_bs\n",
    "                                elif any(keyword in key_spec_bs for keyword in keywords[\"owners\"]):\n",
    "                                    car[\"owners\"] = int(key_spec_bs[:key_spec_bs.find(\" owners\")])\n",
    "                                elif any(keyword in key_spec_bs for keyword in keywords[\"body\"]):\n",
    "                                    car[\"body\"] = key_spec_bs\n",
    "                                elif any(keyword in key_spec_bs for keyword in keywords[\"ULEZ\"]):\n",
    "                                    car[\"ULEZ\"] = key_spec_bs\n",
    "                                elif any(keyword in key_spec_bs for keyword in keywords[\"year\"]):\n",
    "                                    car[\"year\"] = key_spec_bs\n",
    "                                elif key_spec_bs[1] == \".\" and key_spec_bs[3] == \"L\":\n",
    "                                    car[\"engine\"] = float(sub(r'[^\\d.]', '', key_spec_bs))\n",
    "\n",
    "                            results.append(car)\n",
    "                            n_this_year_results = n_this_year_results + 1\n",
    "\n",
    "                        page = page + 1\n",
    "                        attempt = 1\n",
    "\n",
    "                        if verbose:\n",
    "                            print(\"Car count: \", len(results))\n",
    "                            print(\"---------------------------------\")\n",
    "\n",
    "            except KeyboardInterrupt:\n",
    "                break\n",
    "\n",
    "            except:\n",
    "                traceback.print_exc()\n",
    "                attempt = attempt + 1\n",
    "                if attempt <= 5:\n",
    "                    if verbose:\n",
    "                        print(\"Exception. Starting attempt #\", attempt, \"and keeping at page #\", page)\n",
    "                else:\n",
    "                    page = page + 1\n",
    "                    attempt = 1\n",
    "                    if verbose:\n",
    "                        print(\"Exception. All attempts exhausted for this page. Skipping to next page #\", page)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
